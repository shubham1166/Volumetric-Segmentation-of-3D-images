{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NCpW3EzWev1X"
   },
   "source": [
    "# SHUBHAM SHARMA\n",
    "## IIT BOMBAY\n",
    "This code contains a basic model of VGG for 3D MNIST dataset. It can be an introductory code for understanding 3D images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9VpVf2zel6E"
   },
   "outputs": [],
   "source": [
    "#For preparing the dataset\n",
    "import h5py\n",
    "import numpy as np\n",
    "#For making the VGG model\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "k1mZERfBhHxI",
    "outputId": "2445140f-0c18-4bc6-d9f7-0b82a8be995b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of datasets in this file : \n",
      " ['X_test', 'X_train', 'y_test', 'y_train']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"full_dataset_vectors.h5\", \"r\") as hf:   \n",
    "    ls=list(hf.keys())\n",
    "    print('List of datasets in this file : \\n',ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "ETUFA1aSh_G7",
    "outputId": "410e4b6f-6493-4ec5-896b-427204088f0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is : (10000, 1, 16, 16, 16)\n",
      "The shape of y_train is : (10000,)\n",
      "The shape of X_test is : (2000, 1, 16, 16, 16)\n",
      "The shape of y_test is : (2000,)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"full_dataset_vectors.h5\", \"r\") as hf:   \n",
    "    X_train = hf[\"X_train\"][:]\n",
    "    y_train = hf[\"y_train\"][:]    \n",
    "    X_test = hf[\"X_test\"][:]  \n",
    "    y_test = hf[\"y_test\"][:]\n",
    "    \n",
    "X_train=X_train.reshape(10000,1, 16,16,16)\n",
    "X_test=X_test.reshape(2000,1, 16,16,16)\n",
    "print('The shape of X_train is :', X_train.shape)\n",
    "print('The shape of y_train is :', y_train.shape)\n",
    "print('The shape of X_test is :', X_test.shape)\n",
    "print('The shape of y_test is :', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "t3O8MH3Yf-MR",
    "outputId": "2963959b-b3a3-44a2-d677-6b3ce6444c2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max of X_train is : 1.0\n",
      "The min of X_train is : 0.0\n"
     ]
    }
   ],
   "source": [
    "print('The max of X_train is :',np.max(X_train))\n",
    "print('The min of X_train is :',np.min(X_train))\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5A_U0szzmVyN"
   },
   "source": [
    "Lets work on the model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "F1JyvRjtg8UU",
    "outputId": "935ee41d-ac34-446c-d0d9-f12b11af4fa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(7, 5)\n"
     ]
    }
   ],
   "source": [
    "#CHecking the number of GPU and then setting the GPU id\n",
    "print(torch.cuda.current_device())#To know thw current active device\n",
    "print(torch.cuda.get_device_capability())#the major and minor cuda capability of the device\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "XcjCAn23kxRT",
    "outputId": "5993ca7f-67d4-4a4c-8c73-60aaf7efe7e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1       [-1, 64, 16, 16, 16]           1,792\n",
      "       BatchNorm3d-2       [-1, 64, 16, 16, 16]             128\n",
      "              ReLU-3       [-1, 64, 16, 16, 16]               0\n",
      "            Conv3d-4       [-1, 64, 16, 16, 16]         110,656\n",
      "       BatchNorm3d-5       [-1, 64, 16, 16, 16]             128\n",
      "              ReLU-6       [-1, 64, 16, 16, 16]               0\n",
      "         MaxPool3d-7          [-1, 64, 8, 8, 8]               0\n",
      "            Conv3d-8         [-1, 128, 8, 8, 8]         221,312\n",
      "       BatchNorm3d-9         [-1, 128, 8, 8, 8]             256\n",
      "             ReLU-10         [-1, 128, 8, 8, 8]               0\n",
      "           Conv3d-11         [-1, 128, 8, 8, 8]         442,496\n",
      "      BatchNorm3d-12         [-1, 128, 8, 8, 8]             256\n",
      "             ReLU-13         [-1, 128, 8, 8, 8]               0\n",
      "        MaxPool3d-14         [-1, 128, 4, 4, 4]               0\n",
      "           Conv3d-15         [-1, 256, 4, 4, 4]         884,992\n",
      "      BatchNorm3d-16         [-1, 256, 4, 4, 4]             512\n",
      "             ReLU-17         [-1, 256, 4, 4, 4]               0\n",
      "           Conv3d-18         [-1, 256, 4, 4, 4]       1,769,728\n",
      "      BatchNorm3d-19         [-1, 256, 4, 4, 4]             512\n",
      "             ReLU-20         [-1, 256, 4, 4, 4]               0\n",
      "        MaxPool3d-21         [-1, 256, 2, 2, 2]               0\n",
      "           Conv3d-22         [-1, 512, 2, 2, 2]       3,539,456\n",
      "      BatchNorm3d-23         [-1, 512, 2, 2, 2]           1,024\n",
      "             ReLU-24         [-1, 512, 2, 2, 2]               0\n",
      "           Conv3d-25         [-1, 512, 2, 2, 2]       7,078,400\n",
      "      BatchNorm3d-26         [-1, 512, 2, 2, 2]           1,024\n",
      "             ReLU-27         [-1, 512, 2, 2, 2]               0\n",
      "        MaxPool3d-28         [-1, 512, 1, 1, 1]               0\n",
      "           Linear-29                  [-1, 100]          51,300\n",
      "             ReLU-30                  [-1, 100]               0\n",
      "           Linear-31                   [-1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 14,104,982\n",
      "Trainable params: 14,104,982\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 16.27\n",
      "Params size (MB): 53.81\n",
      "Estimated Total Size (MB): 70.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super(Net,self).__init__()\n",
    "    \n",
    "    \n",
    "    #For first layer input=(1,16,16,16)\n",
    "    self.conv1a=nn.Conv3d(in_channels=1, out_channels=64, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "    self.conv1b=nn.Conv3d(in_channels=64, out_channels=64, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "    self.BN1=nn.BatchNorm3d(64)\n",
    "    \n",
    "    #For second layer input=(64,8,8,8)\n",
    "    self.conv2a=nn.Conv3d(in_channels=64, out_channels=128, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "    self.conv2b=nn.Conv3d(in_channels=128, out_channels=128, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "    self.BN2=nn.BatchNorm3d(128)\n",
    "\n",
    "    #For third layer input=(128,4,4,4)\n",
    "    self.conv3a=nn.Conv3d(in_channels=128, out_channels=256, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "    self.conv3b=nn.Conv3d(in_channels=256, out_channels=256, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "    self.BN3=nn.BatchNorm3d(256)\n",
    "\n",
    "    #For forth layer input=(256,2,2,2)\n",
    "    self.conv4a=nn.Conv3d(in_channels=256, out_channels=512, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "    self.conv4b=nn.Conv3d(in_channels=512, out_channels=512, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "    self.BN4=nn.BatchNorm3d(512)\n",
    "    \n",
    "    #Max pool layer\n",
    "    self.max_pool=nn.MaxPool3d(kernel_size=(2,2,2), stride=2)\n",
    "\n",
    "    #Now thw fully connected layers\n",
    "    self.fc1 = nn.Linear(512,100)\n",
    "    self.fc2 = nn.Linear(100,10)\n",
    "    \n",
    "    #Defining activations\n",
    "    self.relu = nn.ReLU()\n",
    "    \n",
    "    ####################################################################\n",
    "  def forward(self,x):\n",
    "    y=self.conv1a(x)\n",
    "    y=self.BN1(y)\n",
    "    y=self.relu(y)\n",
    "    y=self.conv1b(y)\n",
    "    y=self.BN1(y)\n",
    "    y=self.relu(y)\n",
    "    y=self.max_pool(y)\n",
    "    ##\n",
    "    y=self.conv2a(y)\n",
    "    y=self.BN2(y)\n",
    "    y=self.relu(y)\n",
    "    y=self.conv2b(y)\n",
    "    y=self.BN2(y)\n",
    "    y=self.relu(y)\n",
    "    y=self.max_pool(y)\n",
    "    ##\n",
    "    y=self.conv3a(y)\n",
    "    y=self.BN3(y)\n",
    "    y=self.relu(y)\n",
    "    y=self.conv3b(y)\n",
    "    y=self.BN3(y)\n",
    "    y=self.relu(y)\n",
    "    y=self.max_pool(y)\n",
    "    ##\n",
    "    y=self.conv4a(y)\n",
    "    y=self.BN4(y)\n",
    "    y=self.relu(y)\n",
    "    y=self.conv4b(y)\n",
    "    y=self.BN4(y)\n",
    "    y=self.relu(y)\n",
    "    y=self.max_pool(y)\n",
    "    ## Fully Connected Layers\n",
    "    y=y.view(-1, 512)\n",
    "    y=self.fc1(y)\n",
    "    y=self.relu(y)\n",
    "    y=self.fc2(y)\n",
    "    \n",
    "    return y\n",
    "\n",
    "      \n",
    "      \n",
    "##########################################################################\n",
    "model = Net().to(device)#not necessary to add to device\n",
    "summary(model, input_size=(1, 16, 16, 16))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WyUCec5YxHaS"
   },
   "outputs": [],
   "source": [
    "lr=1e-5\n",
    "num_of_epochs=50\n",
    "# Loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()#NO NEED TO BE USING SOFTMAX WHEN USING Crioss Entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9pLUKhn-2i25"
   },
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.TensorDataset(X_train,y_train)# create your datset\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "valset = torch.utils.data.TensorDataset(X_test,y_test)# create your datset\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=True)\n",
    "no_of_epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 906
    },
    "colab_type": "code",
    "id": "-EeOyfEN1f5P",
    "outputId": "b37eeb56-4a36-4b85-ee23-6728d0c3a944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [100/157], Loss: 0.9078\n",
      "Epoch [2/50], Step [100/157], Loss: 0.5899\n",
      "Epoch [3/50], Step [100/157], Loss: 0.5003\n",
      "Epoch [4/50], Step [100/157], Loss: 0.3832\n",
      "Epoch [5/50], Step [100/157], Loss: 0.2903\n",
      "Epoch [6/50], Step [100/157], Loss: 0.2276\n",
      "Epoch [7/50], Step [100/157], Loss: 0.1806\n",
      "Epoch [8/50], Step [100/157], Loss: 0.0388\n",
      "Epoch [9/50], Step [100/157], Loss: 0.1306\n",
      "Epoch [10/50], Step [100/157], Loss: 0.0444\n",
      "Epoch [11/50], Step [100/157], Loss: 0.0170\n",
      "Epoch [12/50], Step [100/157], Loss: 0.1545\n",
      "Epoch [13/50], Step [100/157], Loss: 0.0051\n",
      "Epoch [14/50], Step [100/157], Loss: 0.0427\n",
      "Epoch [15/50], Step [100/157], Loss: 0.0208\n",
      "Epoch [16/50], Step [100/157], Loss: 0.0044\n",
      "Epoch [17/50], Step [100/157], Loss: 0.0674\n",
      "Epoch [18/50], Step [100/157], Loss: 0.0236\n",
      "Epoch [19/50], Step [100/157], Loss: 0.1079\n",
      "Epoch [20/50], Step [100/157], Loss: 0.1335\n",
      "Epoch [21/50], Step [100/157], Loss: 0.0186\n",
      "Epoch [22/50], Step [100/157], Loss: 0.0182\n",
      "Epoch [23/50], Step [100/157], Loss: 0.0424\n",
      "Epoch [24/50], Step [100/157], Loss: 0.0518\n",
      "Epoch [25/50], Step [100/157], Loss: 0.0384\n",
      "Epoch [26/50], Step [100/157], Loss: 0.0877\n",
      "Epoch [27/50], Step [100/157], Loss: 0.0012\n",
      "Epoch [28/50], Step [100/157], Loss: 0.0112\n",
      "Epoch [29/50], Step [100/157], Loss: 0.0176\n",
      "Epoch [30/50], Step [100/157], Loss: 0.0111\n",
      "Epoch [31/50], Step [100/157], Loss: 0.0026\n",
      "Epoch [32/50], Step [100/157], Loss: 0.0585\n",
      "Epoch [33/50], Step [100/157], Loss: 0.0002\n",
      "Epoch [34/50], Step [100/157], Loss: 0.0001\n",
      "Epoch [35/50], Step [100/157], Loss: 0.0001\n",
      "Epoch [36/50], Step [100/157], Loss: 0.0004\n",
      "Epoch [37/50], Step [100/157], Loss: 0.0003\n",
      "Epoch [38/50], Step [100/157], Loss: 0.0000\n",
      "Epoch [39/50], Step [100/157], Loss: 0.0001\n",
      "Epoch [40/50], Step [100/157], Loss: 0.0000\n",
      "Epoch [41/50], Step [100/157], Loss: 0.0000\n",
      "Epoch [42/50], Step [100/157], Loss: 0.0000\n",
      "Epoch [43/50], Step [100/157], Loss: 0.0001\n",
      "Epoch [44/50], Step [100/157], Loss: 0.0001\n",
      "Epoch [45/50], Step [100/157], Loss: 0.0000\n",
      "Epoch [46/50], Step [100/157], Loss: 0.0000\n",
      "Epoch [47/50], Step [100/157], Loss: 0.0001\n",
      "Epoch [48/50], Step [100/157], Loss: 0.0000\n",
      "Epoch [49/50], Step [100/157], Loss: 0.0000\n",
      "Epoch [50/50], Step [100/157], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "total_step = len(trainloader)\n",
    "for epochs in range(num_of_epochs):\n",
    "  for i, (images, labels) in enumerate(trainloader):  \n",
    "    #CHECK THE SHAPE OF BOTH IMAGES AND LABELS\n",
    "    images = images.to(device)\n",
    "    images= images.float()\n",
    "    labels = labels.to(device)  \n",
    "    \n",
    "    #Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    \n",
    "    # Backpropagation and then optimization\n",
    "    optimizer.zero_grad()#Initially setting the gradient values to zero so backward() can find the gradient\n",
    "    loss.backward()#backpropagate and then optimize\n",
    "    optimizer.step()\n",
    "    if (i+1) % 100 == 0:\n",
    "      print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "             .format(epochs+1, num_of_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jy-3Cy6Y1kHN",
    "outputId": "d8d1202d-a4f0-4e4c-b22c-4974c267ccf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 69.9 %\n"
     ]
    }
   ],
   "source": [
    "#For Testing\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "  correct=0\n",
    "  total=0\n",
    "  for images, labels in valloader:\n",
    "    images=images.to(device)\n",
    "    images= images.float()\n",
    "    labels=labels.to(device)\n",
    "    outputs= model(images)\n",
    "    #outputs.data is the output of softmax layer\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "  print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch_3D_MNIST_VGG.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
