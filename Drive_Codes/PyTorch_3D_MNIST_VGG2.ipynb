{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_3D_MNIST_VGG2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjvst4B04jqO",
        "colab_type": "text"
      },
      "source": [
        "# SHUBHAM SHARMA\n",
        "## IIT BOMBAY\n",
        "This code is an improvisation of what we did in the "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQt6TVQLa3mf",
        "colab_type": "code",
        "outputId": "72ed1946-3c2b-4a2c-a35d-93dbc447822a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1BOsKUWbuI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For preparing the dataset\n",
        "import h5py\n",
        "import numpy as np\n",
        "#For making the VGG model\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmymu75aeKXX",
        "colab_type": "code",
        "outputId": "f7d27de3-ec84-450a-8b94-743bcfbbcfa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "path='gdrive/My Drive/data_phase1/'\n",
        "with h5py.File(path+\"full_dataset_vectors.h5\", \"r\") as hf:   \n",
        "    ls=list(hf.keys())\n",
        "    print('List of datasets in this file : \\n',ls)\n",
        "with h5py.File(path+\"full_dataset_vectors.h5\", \"r\") as hf:   \n",
        "    X_train = hf[\"X_train\"][:]\n",
        "    y_train = hf[\"y_train\"][:]    \n",
        "    X_test = hf[\"X_test\"][:]  \n",
        "    y_test = hf[\"y_test\"][:]\n",
        "    \n",
        "X_train=X_train.reshape(10000,1, 16,16,16)\n",
        "X_test=X_test.reshape(2000,1, 16,16,16)\n",
        "print('The shape of X_train is :', X_train.shape)\n",
        "print('The shape of y_train is :', y_train.shape)\n",
        "print('The shape of X_test is :', X_test.shape)\n",
        "print('The shape of y_test is :', y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List of datasets in this file : \n",
            " ['X_test', 'X_train', 'y_test', 'y_train']\n",
            "The shape of X_train is : (10000, 1, 16, 16, 16)\n",
            "The shape of y_train is : (10000,)\n",
            "The shape of X_test is : (2000, 1, 16, 16, 16)\n",
            "The shape of y_test is : (2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmrR4F5ieoQd",
        "colab_type": "code",
        "outputId": "a6b2164e-b795-4cc1-fa24-95f9ff0e9959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "x=X_train[7,0]\n",
        "def show_slices(slices):\n",
        "# Function to display row of image slices\n",
        "  fig, axes = plt.subplots(1, len(slices))\n",
        "  for i, slice in enumerate(slices):\n",
        "    axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")\n",
        "    \n",
        "slice_0 = x[8, :, :]\n",
        "slice_1 = x[:, 8, :]\n",
        "slice_2 = x[:, :, 8]\n",
        "show_slices([slice_0, slice_1, slice_2])\n",
        "plt.suptitle(\"Center slices for image\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0.98, 'Center slices for image')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADaCAYAAAC2Arl5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTlG4et2lAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-yOJbRqfLL9",
        "colab_type": "code",
        "outputId": "9da5779a-3d6e-4007-e338-181be16fbeb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('The max of X_train is :',np.max(X_train))\n",
        "print('The min of X_train is :',np.min(X_train))\n",
        "X_train = torch.from_numpy(X_train)\n",
        "X_test = torch.from_numpy(X_test)\n",
        "y_train = torch.from_numpy(y_train)\n",
        "y_test = torch.from_numpy(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The max of X_train is : 1.0\n",
            "The min of X_train is : 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Hh3Zlb9ocM",
        "colab_type": "code",
        "outputId": "287fd26b-ed6b-4745-8a1c-0f3c476870de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#CHecking the number of GPU and then setting the GPU id\n",
        "print(torch.cuda.current_device())#To know thw current active device\n",
        "print(torch.cuda.get_device_capability())#the major and minor cuda capability of the device\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "(3, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTpX3RMY9rOf",
        "colab_type": "code",
        "outputId": "74ec7c56-dff6-4831-e0ae-a46e38ceed4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "#Defining the variables\n",
        "#Let the input layer is of depth 2 \n",
        "inp=8\n",
        "#No of elements in the first fully connected layer\n",
        "fully_connected_1=20\n",
        "#No of elements in the output layer\n",
        "n_labels=10\n",
        "# Defining probabilities for dropouts\n",
        "prob=0.2\n",
        "\n",
        "#for flattening\n",
        "def find_size(y):\n",
        "  s=y.size()\n",
        "  mul=s[1]*s[2]*s[3]*s[4]\n",
        "  return mul\n",
        "\n",
        "###################################################################################\n",
        "class Net(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    \n",
        "    \n",
        "    #For first layer input\n",
        "    self.conv1a=nn.Conv3d(in_channels=1, out_channels=inp, kernel_size=(3,3,3), stride=1, padding=1)\n",
        "    self.conv1b=nn.Conv3d(in_channels=inp, out_channels=inp, kernel_size=(3,3,3), stride=1, padding=1)\n",
        "    self.BN1=nn.BatchNorm3d(inp)\n",
        "    \n",
        "    #For second layer input\n",
        "    self.conv2a=nn.Conv3d(in_channels=inp, out_channels=2*inp, kernel_size=(3,3,3), stride=1, padding=1)\n",
        "    self.conv2b=nn.Conv3d(in_channels=2*inp, out_channels=2*inp, kernel_size=(3,3,3), stride=1, padding=1)\n",
        "    self.BN2=nn.BatchNorm3d(2*inp)\n",
        "\n",
        "    #For third layer input\n",
        "    self.conv3a=nn.Conv3d(in_channels=2*inp, out_channels=2*2*inp, kernel_size=(3,3,3), stride=1, padding=1)\n",
        "#     self.conv3a=nn.Conv3d(in_channels=2*inp, out_channels=2*inp, kernel_size=(3,3,3), stride=1, padding=1)\n",
        "    self.conv3b=nn.Conv3d(in_channels=2*2*inp, out_channels=2*2*inp, kernel_size=(3,3,3), stride=1, padding=1)\n",
        "    self.BN3=nn.BatchNorm3d(2*2*inp)\n",
        "\n",
        "    #For forth layer input\n",
        "    self.conv4a=nn.Conv3d(in_channels=2*2*inp, out_channels=2*2*2*inp, kernel_size=(3,3,3), stride=1, padding=1)\n",
        "    self.conv4b=nn.Conv3d(in_channels=2*2*2*inp, out_channels=2*2*2*inp, kernel_size=(3,3,3), stride=1, padding=1)\n",
        "    self.BN4=nn.BatchNorm3d(2*2*2*inp)\n",
        "    \n",
        "    #Max pool layer\n",
        "    self.max_pool=nn.MaxPool3d(kernel_size=(2,2,2), stride=2)\n",
        "\n",
        "    #Now thw fully connected layers\n",
        "    #chane value as per the result of flat\n",
        "    self.fc1 = nn.Linear(2048,fully_connected_1)\n",
        "    self.fc2 = nn.Linear(fully_connected_1,n_labels)\n",
        "    \n",
        "    #Defining activations\n",
        "    self.relu = nn.ReLU()\n",
        "    \n",
        "    \n",
        "    #Defining dropoutsA\n",
        "    self.dout = nn.Dropout(p=prob)\n",
        "    \n",
        "    ####################################################################\n",
        "  def forward(self,x):\n",
        "    y=self.conv1a(x)\n",
        "    y=self.BN1(y)\n",
        "    y=self.relu(y)\n",
        "    y=self.conv1b(y)\n",
        "    y=self.BN1(y)\n",
        "    y=self.relu(y)\n",
        "    y=self.max_pool(y)\n",
        "    ##\n",
        "    y=self.conv2a(y)\n",
        "    y=self.BN2(y)\n",
        "    y=self.relu(y)\n",
        "    y=self.conv2b(y)\n",
        "    y=self.BN2(y)\n",
        "    y=self.relu(y)\n",
        "    y=self.max_pool(y)\n",
        "#     ##\n",
        "    y=self.conv3a(y)\n",
        "    y=self.BN3(y)\n",
        "    y=self.relu(y)\n",
        "#     y=self.conv3b(y)\n",
        "#     y=self.BN3(y)\n",
        "#     y=self.relu(y)\n",
        "#     y=self.max_pool(y)\n",
        "    ##\n",
        "#     y=self.conv4a(y)\n",
        "#     y=self.BN4(y)\n",
        "#     y=self.relu(y)\n",
        "#     y=self.conv4b(y)\n",
        "#     y=self.BN4(y)\n",
        "#     y=self.relu(y)\n",
        "#     y=self.max_pool(y)\n",
        "  \n",
        "  \n",
        "    flat= find_size(y)\n",
        "#     print('The number of nodes in the falttened output',flat)\n",
        "    # Fully Connected Layers\n",
        "    y=y.view(-1,flat)\n",
        "    y=self.fc1(y)\n",
        "    y=self.relu(y)\n",
        "    y=self.dout(y)\n",
        "    y=self.fc2(y)\n",
        "    return y\n",
        "\n",
        "      \n",
        "      \n",
        "##########################################################################\n",
        "model = Net().to(device)#not necessary to add to device\n",
        "summary(model, input_size=(1, 16, 16, 16))\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1        [-1, 8, 16, 16, 16]             224\n",
            "       BatchNorm3d-2        [-1, 8, 16, 16, 16]              16\n",
            "              ReLU-3        [-1, 8, 16, 16, 16]               0\n",
            "            Conv3d-4        [-1, 8, 16, 16, 16]           1,736\n",
            "       BatchNorm3d-5        [-1, 8, 16, 16, 16]              16\n",
            "              ReLU-6        [-1, 8, 16, 16, 16]               0\n",
            "         MaxPool3d-7           [-1, 8, 8, 8, 8]               0\n",
            "            Conv3d-8          [-1, 16, 8, 8, 8]           3,472\n",
            "       BatchNorm3d-9          [-1, 16, 8, 8, 8]              32\n",
            "             ReLU-10          [-1, 16, 8, 8, 8]               0\n",
            "           Conv3d-11          [-1, 16, 8, 8, 8]           6,928\n",
            "      BatchNorm3d-12          [-1, 16, 8, 8, 8]              32\n",
            "             ReLU-13          [-1, 16, 8, 8, 8]               0\n",
            "        MaxPool3d-14          [-1, 16, 4, 4, 4]               0\n",
            "           Conv3d-15          [-1, 32, 4, 4, 4]          13,856\n",
            "      BatchNorm3d-16          [-1, 32, 4, 4, 4]              64\n",
            "             ReLU-17          [-1, 32, 4, 4, 4]               0\n",
            "           Linear-18                   [-1, 20]          40,980\n",
            "             ReLU-19                   [-1, 20]               0\n",
            "          Dropout-20                   [-1, 20]               0\n",
            "           Linear-21                   [-1, 10]             210\n",
            "================================================================\n",
            "Total params: 67,566\n",
            "Trainable params: 67,566\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.02\n",
            "Forward/backward pass size (MB): 1.96\n",
            "Params size (MB): 0.26\n",
            "Estimated Total Size (MB): 2.23\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyq9f34UGurT",
        "colab_type": "code",
        "outputId": "abc28c03-4917-42fd-bc15-82ac88308301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "lr=1e-6\n",
        "num_of_epochs=200\n",
        "batch_size=64\n",
        "# Loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()#NO NEED TO BE USING SOFTMAX WHEN USING Crioss Entropy loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)  \n",
        "\n",
        "trainset = torch.utils.data.TensorDataset(X_train,y_train)# create your datset\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "valset = torch.utils.data.TensorDataset(X_test,y_test)# create your datset\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=True)\n",
        "\n",
        "#Training the model\n",
        "total_step = len(trainloader)\n",
        "for epochs in range(num_of_epochs):\n",
        "  for i, (images, labels) in enumerate(trainloader):  \n",
        "    #CHECK THE SHAPE OF BOTH IMAGES AND LABELS\n",
        "    images = images.to(device)\n",
        "    images= images.float()\n",
        "    labels = labels.to(device)  \n",
        "    \n",
        "    #Forward pass\n",
        "    outputs = model(images)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    \n",
        "    # Backpropagation and then optimization\n",
        "    optimizer.zero_grad()#Initially setting the gradient values to zero so backward() can find the gradient\n",
        "    loss.backward()#backpropagate and then optimize\n",
        "    optimizer.step()\n",
        "    if (i+1) % 100 == 0:\n",
        "      print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "             .format(epochs+1, num_of_epochs, i+1, total_step, loss.item()))\n",
        "      \n",
        "      \n",
        "################################\n",
        "#For testing\n",
        "#For Testing\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "  correct=0\n",
        "  total=0\n",
        "  for images, labels in valloader:\n",
        "    images=images.to(device)\n",
        "    images= images.float()\n",
        "    labels=labels.to(device)\n",
        "    outputs= model(images)\n",
        "    #outputs.data is the output of softmax layer\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    \n",
        "  print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/200], Step [100/157], Loss: 0.2578\n",
            "Epoch [2/200], Step [100/157], Loss: 0.3425\n",
            "Epoch [3/200], Step [100/157], Loss: 0.3893\n",
            "Epoch [4/200], Step [100/157], Loss: 0.3673\n",
            "Epoch [5/200], Step [100/157], Loss: 0.3796\n",
            "Epoch [6/200], Step [100/157], Loss: 0.3424\n",
            "Epoch [7/200], Step [100/157], Loss: 0.2454\n",
            "Epoch [8/200], Step [100/157], Loss: 0.4086\n",
            "Epoch [9/200], Step [100/157], Loss: 0.3921\n",
            "Epoch [10/200], Step [100/157], Loss: 0.3090\n",
            "Epoch [11/200], Step [100/157], Loss: 0.3559\n",
            "Epoch [12/200], Step [100/157], Loss: 0.5155\n",
            "Epoch [13/200], Step [100/157], Loss: 0.4041\n",
            "Epoch [14/200], Step [100/157], Loss: 0.2244\n",
            "Epoch [15/200], Step [100/157], Loss: 0.2963\n",
            "Epoch [16/200], Step [100/157], Loss: 0.3966\n",
            "Epoch [17/200], Step [100/157], Loss: 0.4325\n",
            "Epoch [18/200], Step [100/157], Loss: 0.4752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-c6199b769a03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#CHECK THE SHAPE OF BOTH IMAGES AND LABELS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtWjxvnywKjn",
        "colab_type": "code",
        "outputId": "49d09ea9-6d64-49b4-98e8-35d6c93bcf22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "################################\n",
        "#For testing\n",
        "#For Testing\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "  correct=0\n",
        "  total=0\n",
        "  for images, labels in valloader:\n",
        "    images=images.to(device)\n",
        "    images= images.float()\n",
        "    labels=labels.to(device)\n",
        "    outputs= model(images)\n",
        "    #outputs.data is the output of softmax layer\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    \n",
        "  print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 60.35 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x997WJ9s_z1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEJ5qMJMZ9mD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}