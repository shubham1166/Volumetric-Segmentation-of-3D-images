{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJjHyOCykyM2",
        "colab_type": "text"
      },
      "source": [
        "# Shubham Sharma \n",
        "This code will be a basic code of classification in MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gy9akTZkRiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing the functions\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "import numpy as np\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxHvroEY67kh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f7fa63d7-4aed-493b-fb8a-ffff766a7359"
      },
      "source": [
        "#CHecking the number of GPU and then setting the GPU id\n",
        "print(torch.cuda.current_device())#To know thw current active device\n",
        "print(torch.cuda.get_device_capability())#the major and minor cuda capability of the device\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "(7, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FS4jcD0qkET",
        "colab_type": "text"
      },
      "source": [
        "Before downloading the data, let us define what are the transformations we want to perform on our data before feeding it into the pipeline. In other words, you can consider it to be some kind of custom edit to are performing to the images so that all the images have the same dimensions and properties. We do it using **torchvision.transforms**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jevjYG6iqfiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlqiBwNHq2Hq",
        "colab_type": "text"
      },
      "source": [
        "**transforms.ToTensor()** :— converts the image into numbers, that are understandable by the system. It separates the image into three color channels (separate images): red, green & blue. Then it converts the pixels of each image to the brightness of their color between 0 and 255. These values are then scaled down to a range between 0 and 1. The image is now a Torch Tensor.\n",
        "\n",
        "**transforms.Normalize()**: — normalizes the tensor with a mean and standard deviation which goes as the two parameters respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CtLWynDmrWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "0e889b9f-6584-4544-c143-e1435e8dabe2"
      },
      "source": [
        "#Now downloading the data and passing it to the Dataloader\n",
        "\n",
        "trainset = datasets.MNIST('.data/train', download=True, train=True, transform=transform)\n",
        "\n",
        "valset = datasets.MNIST('.data/test', download=True, train=False, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to .data/train/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 20839362.83it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting .data/train/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 317265.90it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to .data/train/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting .data/train/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to .data/train/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 5321340.63it/s]                           \n",
            "8192it [00:00, 128429.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting .data/train/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to .data/train/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting .data/train/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 16384/9912422 [00:00<01:24, 117550.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to .data/test/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 23965333.86it/s]                           \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting .data/test/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 331223.69it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to .data/test/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting .data/test/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to .data/test/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 5265600.61it/s]                           \n",
            "8192it [00:00, 130972.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting .data/test/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to .data/test/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting .data/test/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOAygiAYtcEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cc991bd6-8046-4939-d299-0a98734ebd68"
      },
      "source": [
        "#Let us see the shape of the images and labels\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBJQxSdpt2cg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "a9550cf2-c11b-4068-e197-ecdc35315a17"
      },
      "source": [
        "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r');"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsXVCDrkGLQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zi6zYUIuFPf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "95d585dc-e8c8-4fc2-ddc5-a26287384ba4"
      },
      "source": [
        "#Making the model\n",
        "class Net(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    # 1 input image channel, 6 output image channel, 3x3 square convolution\n",
        "    self.conv1=nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), stride=1, padding=1)\n",
        "    self.conv2=nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=1, padding=1)\n",
        "    self.max1=nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
        "    \n",
        "    #Defining fully connected laYers\n",
        "    self.fc1= nn.Linear(14*14*16,100)\n",
        "    self.fc2= nn.Linear(100,10)\n",
        "    \n",
        "    #Defining activations\n",
        "    self.relu = nn.ReLU()\n",
        "  \n",
        "  def forward(self,x):\n",
        "    y=self.conv1(x)\n",
        "    y=self.relu(y)\n",
        "    y=self.conv2(y)\n",
        "    y=self.relu(y)\n",
        "    y=self.max1(y)\n",
        "    y=y.view(-1, 14*14*16)\n",
        "    y=self.fc1(y)\n",
        "    y=self.relu(y)\n",
        "    y=self.fc2(y)\n",
        "    return y\n",
        "\n",
        "##########################################################################\n",
        "model = Net().to(device)#not necessary to add to device\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "              ReLU-2            [-1, 8, 28, 28]               0\n",
            "            Conv2d-3           [-1, 16, 28, 28]           1,168\n",
            "              ReLU-4           [-1, 16, 28, 28]               0\n",
            "         MaxPool2d-5           [-1, 16, 14, 14]               0\n",
            "            Linear-6                  [-1, 100]         313,700\n",
            "              ReLU-7                  [-1, 100]               0\n",
            "            Linear-8                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 315,958\n",
            "Trainable params: 315,958\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.31\n",
            "Params size (MB): 1.21\n",
            "Estimated Total Size (MB): 1.52\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44k0Ie0Q64yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr=1e-2\n",
        "num_of_epochs=20\n",
        "# Loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1flNDyskDBNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5cc9f896-e350-44eb-cac2-879b1275255f"
      },
      "source": [
        "#Training the model\n",
        "total_step = len(trainloader)\n",
        "for epochs in range(num_of_epochs):\n",
        "  for i, (images, labels) in enumerate(trainloader):  \n",
        "    #CHECK THE SHAPE OF BOTH IMAGES AND LABELS\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)  \n",
        "    \n",
        "    #Forward pass\n",
        "    outputs = model(images)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    \n",
        "    # Backpropagation and then optimization\n",
        "    optimizer.zero_grad()#Initially setting the gradient values to zero so backward() can find the gradient\n",
        "    loss.backward()#backpropagate and then optimize\n",
        "    optimizer.step()\n",
        "    if (i+1) % 100 == 0:\n",
        "      print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "             .format(epochs+1, num_of_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Step [100/938], Loss: 0.0852\n",
            "Epoch [1/20], Step [200/938], Loss: 0.1205\n",
            "Epoch [1/20], Step [300/938], Loss: 0.3800\n",
            "Epoch [1/20], Step [400/938], Loss: 0.1782\n",
            "Epoch [1/20], Step [500/938], Loss: 0.2178\n",
            "Epoch [1/20], Step [600/938], Loss: 0.2247\n",
            "Epoch [1/20], Step [700/938], Loss: 0.0387\n",
            "Epoch [1/20], Step [800/938], Loss: 0.0404\n",
            "Epoch [1/20], Step [900/938], Loss: 0.0305\n",
            "Epoch [2/20], Step [100/938], Loss: 0.0677\n",
            "Epoch [2/20], Step [200/938], Loss: 0.1785\n",
            "Epoch [2/20], Step [300/938], Loss: 0.0210\n",
            "Epoch [2/20], Step [400/938], Loss: 0.0393\n",
            "Epoch [2/20], Step [500/938], Loss: 0.0344\n",
            "Epoch [2/20], Step [600/938], Loss: 0.0166\n",
            "Epoch [2/20], Step [700/938], Loss: 0.0716\n",
            "Epoch [2/20], Step [800/938], Loss: 0.0692\n",
            "Epoch [2/20], Step [900/938], Loss: 0.0141\n",
            "Epoch [3/20], Step [100/938], Loss: 0.0054\n",
            "Epoch [3/20], Step [200/938], Loss: 0.0051\n",
            "Epoch [3/20], Step [300/938], Loss: 0.0411\n",
            "Epoch [3/20], Step [400/938], Loss: 0.0464\n",
            "Epoch [3/20], Step [500/938], Loss: 0.1044\n",
            "Epoch [3/20], Step [600/938], Loss: 0.0070\n",
            "Epoch [3/20], Step [700/938], Loss: 0.0146\n",
            "Epoch [3/20], Step [800/938], Loss: 0.0514\n",
            "Epoch [3/20], Step [900/938], Loss: 0.0285\n",
            "Epoch [4/20], Step [100/938], Loss: 0.0332\n",
            "Epoch [4/20], Step [200/938], Loss: 0.0010\n",
            "Epoch [4/20], Step [300/938], Loss: 0.0638\n",
            "Epoch [4/20], Step [400/938], Loss: 0.0009\n",
            "Epoch [4/20], Step [500/938], Loss: 0.0003\n",
            "Epoch [4/20], Step [600/938], Loss: 0.0234\n",
            "Epoch [4/20], Step [700/938], Loss: 0.0560\n",
            "Epoch [4/20], Step [800/938], Loss: 0.0900\n",
            "Epoch [4/20], Step [900/938], Loss: 0.0706\n",
            "Epoch [5/20], Step [100/938], Loss: 0.0003\n",
            "Epoch [5/20], Step [200/938], Loss: 0.0214\n",
            "Epoch [5/20], Step [300/938], Loss: 0.0462\n",
            "Epoch [5/20], Step [400/938], Loss: 0.0335\n",
            "Epoch [5/20], Step [500/938], Loss: 0.0066\n",
            "Epoch [5/20], Step [600/938], Loss: 0.0154\n",
            "Epoch [5/20], Step [700/938], Loss: 0.0486\n",
            "Epoch [5/20], Step [800/938], Loss: 0.0799\n",
            "Epoch [5/20], Step [900/938], Loss: 0.1815\n",
            "Epoch [6/20], Step [100/938], Loss: 0.0124\n",
            "Epoch [6/20], Step [200/938], Loss: 0.0000\n",
            "Epoch [6/20], Step [300/938], Loss: 0.1586\n",
            "Epoch [6/20], Step [400/938], Loss: 0.0207\n",
            "Epoch [6/20], Step [500/938], Loss: 0.0243\n",
            "Epoch [6/20], Step [600/938], Loss: 0.0051\n",
            "Epoch [6/20], Step [700/938], Loss: 0.0960\n",
            "Epoch [6/20], Step [800/938], Loss: 0.0432\n",
            "Epoch [6/20], Step [900/938], Loss: 0.0017\n",
            "Epoch [7/20], Step [100/938], Loss: 0.0672\n",
            "Epoch [7/20], Step [200/938], Loss: 0.0111\n",
            "Epoch [7/20], Step [300/938], Loss: 0.0141\n",
            "Epoch [7/20], Step [400/938], Loss: 0.0335\n",
            "Epoch [7/20], Step [500/938], Loss: 0.0074\n",
            "Epoch [7/20], Step [600/938], Loss: 0.0326\n",
            "Epoch [7/20], Step [700/938], Loss: 0.0003\n",
            "Epoch [7/20], Step [800/938], Loss: 0.0003\n",
            "Epoch [7/20], Step [900/938], Loss: 0.1379\n",
            "Epoch [8/20], Step [100/938], Loss: 0.0117\n",
            "Epoch [8/20], Step [200/938], Loss: 0.0332\n",
            "Epoch [8/20], Step [300/938], Loss: 0.0009\n",
            "Epoch [8/20], Step [400/938], Loss: 0.2164\n",
            "Epoch [8/20], Step [500/938], Loss: 0.0002\n",
            "Epoch [8/20], Step [600/938], Loss: 0.0363\n",
            "Epoch [8/20], Step [700/938], Loss: 0.0217\n",
            "Epoch [8/20], Step [800/938], Loss: 0.0007\n",
            "Epoch [8/20], Step [900/938], Loss: 0.0088\n",
            "Epoch [9/20], Step [100/938], Loss: 0.0007\n",
            "Epoch [9/20], Step [200/938], Loss: 0.0047\n",
            "Epoch [9/20], Step [300/938], Loss: 0.0322\n",
            "Epoch [9/20], Step [400/938], Loss: 0.0022\n",
            "Epoch [9/20], Step [500/938], Loss: 0.0007\n",
            "Epoch [9/20], Step [600/938], Loss: 0.0017\n",
            "Epoch [9/20], Step [700/938], Loss: 0.0587\n",
            "Epoch [9/20], Step [800/938], Loss: 0.0356\n",
            "Epoch [9/20], Step [900/938], Loss: 0.0133\n",
            "Epoch [10/20], Step [100/938], Loss: 0.1206\n",
            "Epoch [10/20], Step [200/938], Loss: 0.0098\n",
            "Epoch [10/20], Step [300/938], Loss: 0.0558\n",
            "Epoch [10/20], Step [400/938], Loss: 0.1196\n",
            "Epoch [10/20], Step [500/938], Loss: 0.0025\n",
            "Epoch [10/20], Step [600/938], Loss: 0.0407\n",
            "Epoch [10/20], Step [700/938], Loss: 0.0049\n",
            "Epoch [10/20], Step [800/938], Loss: 0.0007\n",
            "Epoch [10/20], Step [900/938], Loss: 0.0000\n",
            "Epoch [11/20], Step [100/938], Loss: 0.0003\n",
            "Epoch [11/20], Step [200/938], Loss: 0.0148\n",
            "Epoch [11/20], Step [300/938], Loss: 0.0026\n",
            "Epoch [11/20], Step [400/938], Loss: 0.0052\n",
            "Epoch [11/20], Step [500/938], Loss: 0.1185\n",
            "Epoch [11/20], Step [600/938], Loss: 0.1114\n",
            "Epoch [11/20], Step [700/938], Loss: 0.0625\n",
            "Epoch [11/20], Step [800/938], Loss: 0.0003\n",
            "Epoch [11/20], Step [900/938], Loss: 0.0392\n",
            "Epoch [12/20], Step [100/938], Loss: 0.0008\n",
            "Epoch [12/20], Step [200/938], Loss: 0.0631\n",
            "Epoch [12/20], Step [300/938], Loss: 0.0066\n",
            "Epoch [12/20], Step [400/938], Loss: 0.0229\n",
            "Epoch [12/20], Step [500/938], Loss: 0.0107\n",
            "Epoch [12/20], Step [600/938], Loss: 0.0021\n",
            "Epoch [12/20], Step [700/938], Loss: 0.0440\n",
            "Epoch [12/20], Step [800/938], Loss: 0.0071\n",
            "Epoch [12/20], Step [900/938], Loss: 0.0073\n",
            "Epoch [13/20], Step [100/938], Loss: 0.0186\n",
            "Epoch [13/20], Step [200/938], Loss: 0.0002\n",
            "Epoch [13/20], Step [300/938], Loss: 0.0304\n",
            "Epoch [13/20], Step [400/938], Loss: 0.0006\n",
            "Epoch [13/20], Step [500/938], Loss: 0.0437\n",
            "Epoch [13/20], Step [600/938], Loss: 0.1031\n",
            "Epoch [13/20], Step [700/938], Loss: 0.0004\n",
            "Epoch [13/20], Step [800/938], Loss: 0.0003\n",
            "Epoch [13/20], Step [900/938], Loss: 0.0001\n",
            "Epoch [14/20], Step [100/938], Loss: 0.0534\n",
            "Epoch [14/20], Step [200/938], Loss: 0.0055\n",
            "Epoch [14/20], Step [300/938], Loss: 0.0001\n",
            "Epoch [14/20], Step [400/938], Loss: 0.0138\n",
            "Epoch [14/20], Step [500/938], Loss: 0.0441\n",
            "Epoch [14/20], Step [600/938], Loss: 0.0700\n",
            "Epoch [14/20], Step [700/938], Loss: 0.0056\n",
            "Epoch [14/20], Step [800/938], Loss: 0.0957\n",
            "Epoch [14/20], Step [900/938], Loss: 0.0099\n",
            "Epoch [15/20], Step [100/938], Loss: 0.0068\n",
            "Epoch [15/20], Step [200/938], Loss: 0.0000\n",
            "Epoch [15/20], Step [300/938], Loss: 0.0138\n",
            "Epoch [15/20], Step [400/938], Loss: 0.0646\n",
            "Epoch [15/20], Step [500/938], Loss: 0.0455\n",
            "Epoch [15/20], Step [600/938], Loss: 0.0314\n",
            "Epoch [15/20], Step [700/938], Loss: 0.0011\n",
            "Epoch [15/20], Step [800/938], Loss: 0.0004\n",
            "Epoch [15/20], Step [900/938], Loss: 0.0894\n",
            "Epoch [16/20], Step [100/938], Loss: 0.0031\n",
            "Epoch [16/20], Step [200/938], Loss: 0.0744\n",
            "Epoch [16/20], Step [300/938], Loss: 0.0045\n",
            "Epoch [16/20], Step [400/938], Loss: 0.0361\n",
            "Epoch [16/20], Step [500/938], Loss: 0.0002\n",
            "Epoch [16/20], Step [600/938], Loss: 0.0005\n",
            "Epoch [16/20], Step [700/938], Loss: 0.0000\n",
            "Epoch [16/20], Step [800/938], Loss: 0.0005\n",
            "Epoch [16/20], Step [900/938], Loss: 0.0069\n",
            "Epoch [17/20], Step [100/938], Loss: 0.0280\n",
            "Epoch [17/20], Step [200/938], Loss: 0.0029\n",
            "Epoch [17/20], Step [300/938], Loss: 0.0013\n",
            "Epoch [17/20], Step [400/938], Loss: 0.0141\n",
            "Epoch [17/20], Step [500/938], Loss: 0.0000\n",
            "Epoch [17/20], Step [600/938], Loss: 0.1660\n",
            "Epoch [17/20], Step [700/938], Loss: 0.0002\n",
            "Epoch [17/20], Step [800/938], Loss: 0.0025\n",
            "Epoch [17/20], Step [900/938], Loss: 0.0023\n",
            "Epoch [18/20], Step [100/938], Loss: 0.0430\n",
            "Epoch [18/20], Step [200/938], Loss: 0.0001\n",
            "Epoch [18/20], Step [300/938], Loss: 0.0269\n",
            "Epoch [18/20], Step [400/938], Loss: 0.0681\n",
            "Epoch [18/20], Step [500/938], Loss: 0.0285\n",
            "Epoch [18/20], Step [600/938], Loss: 0.0084\n",
            "Epoch [18/20], Step [700/938], Loss: 0.0045\n",
            "Epoch [18/20], Step [800/938], Loss: 0.0005\n",
            "Epoch [18/20], Step [900/938], Loss: 0.0001\n",
            "Epoch [19/20], Step [100/938], Loss: 0.0383\n",
            "Epoch [19/20], Step [200/938], Loss: 0.0434\n",
            "Epoch [19/20], Step [300/938], Loss: 0.0001\n",
            "Epoch [19/20], Step [400/938], Loss: 0.0011\n",
            "Epoch [19/20], Step [500/938], Loss: 0.0008\n",
            "Epoch [19/20], Step [600/938], Loss: 0.0001\n",
            "Epoch [19/20], Step [700/938], Loss: 0.0250\n",
            "Epoch [19/20], Step [800/938], Loss: 0.0013\n",
            "Epoch [19/20], Step [900/938], Loss: 0.0008\n",
            "Epoch [20/20], Step [100/938], Loss: 0.0598\n",
            "Epoch [20/20], Step [200/938], Loss: 0.0062\n",
            "Epoch [20/20], Step [300/938], Loss: 0.0004\n",
            "Epoch [20/20], Step [400/938], Loss: 0.0144\n",
            "Epoch [20/20], Step [500/938], Loss: 0.0708\n",
            "Epoch [20/20], Step [600/938], Loss: 0.1296\n",
            "Epoch [20/20], Step [700/938], Loss: 0.0659\n",
            "Epoch [20/20], Step [800/938], Loss: 0.0000\n",
            "Epoch [20/20], Step [900/938], Loss: 0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqz7DdiXMM22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5f70c505-27d6-4e83-facd-809a958ad66a"
      },
      "source": [
        "#For Testing\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "  correct=0\n",
        "  total=0\n",
        "  for images, labels in valloader:\n",
        "    images=images.to(device)\n",
        "    labels=labels.to(device)\n",
        "    outputs= model(images)\n",
        "    #outputs.data is the output of softmax layer\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    \n",
        "  print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "  "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 98.06 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8MI_b5KXeht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c6192582-6cb3-423d-fc12-b0152d19ff8a"
      },
      "source": [
        "# Save the model checkpoint\n",
        "torch.save(model, './model')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfvYmyeVYpZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}