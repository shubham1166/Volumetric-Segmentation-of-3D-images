{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHUBHAM SHARMA\n",
    "## IIT BOMBAY\n",
    "This code is a pytorch implimentation of the U-Net architecture that we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the functions for U-net\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "# from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "#CHecking the number of GPU and then setting the GPU id\n",
    "print(torch.cuda.current_device())#To know thw current active device\n",
    "device = torch.device('cuda:1')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes=2\n",
    "# input_size=(1, 128, 128, 128)\n",
    "# input_size[1]*input_size[2]*input_size[3]\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        \n",
    "        \n",
    "        #For first layer input\n",
    "        self.conv1a=nn.Conv3d(in_channels=1, out_channels=32, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv1b=nn.Conv3d(in_channels=32, out_channels=32, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.BN1=nn.BatchNorm3d(32)\n",
    "        \n",
    "        #For second layer \n",
    "        self.conv2a=nn.Conv3d(in_channels=32, out_channels=64, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv2b=nn.Conv3d(in_channels=64, out_channels=64, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.BN2=nn.BatchNorm3d(64)\n",
    "        \n",
    "        #For third layer \n",
    "        self.conv3a=nn.Conv3d(in_channels=64, out_channels=128, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv3b=nn.Conv3d(in_channels=128, out_channels=128, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.BN3=nn.BatchNorm3d(128)\n",
    "        \n",
    "        #For forth layer \n",
    "        self.conv4a=nn.Conv3d(in_channels=128, out_channels=256, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv4b=nn.Conv3d(in_channels=256, out_channels=256, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.BN4=nn.BatchNorm3d(256)\n",
    "        \n",
    "        #For fifth/latent layer \n",
    "        self.conv5a=nn.Conv3d(in_channels=256, out_channels=512, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv5b=nn.Conv3d(in_channels=512, out_channels=512, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        \n",
    "        #For Upsampling/ sixth layer\n",
    "        self.upconv1=nn.ConvTranspose3d(in_channels=512, out_channels=256, kernel_size=(2,2,2), stride=2, padding=0)\n",
    "        self.conv6a=nn.Conv3d(in_channels=512, out_channels=256, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv6b=nn.Conv3d(in_channels=256, out_channels=256, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        \n",
    "        #For Upsampling/ seventh layer\n",
    "        self.upconv2=nn.ConvTranspose3d(in_channels=256, out_channels=128, kernel_size=(2,2,2), stride=2, padding=0)\n",
    "        self.conv7a=nn.Conv3d(in_channels=256, out_channels=128, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv7b=nn.Conv3d(in_channels=128, out_channels=128, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        \n",
    "        #For Upsampling/ eighth layer\n",
    "        self.upconv3=nn.ConvTranspose3d(in_channels=128, out_channels=64, kernel_size=(2,2,2), stride=2, padding=0)\n",
    "        self.conv8a=nn.Conv3d(in_channels=128, out_channels=64, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv8b=nn.Conv3d(in_channels=64, out_channels=64, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "\n",
    "        #For Upsampling/ ninth layer\n",
    "        self.upconv4=nn.ConvTranspose3d(in_channels=64, out_channels=32, kernel_size=(2,2,2), stride=2, padding=0)\n",
    "        self.conv9a=nn.Conv3d(in_channels=64, out_channels=32, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv9b=nn.Conv3d(in_channels=32, out_channels=32, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        \n",
    "        #For last layer\n",
    "        self.convLast=nn.Conv3d(in_channels=32, out_channels=num_of_classes, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        \n",
    "        #For maxpool\n",
    "        self.max_pool=nn.MaxPool3d(kernel_size=(2,2,2), stride=2)\n",
    "        \n",
    "        #For activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        conv1 = self.conv1a(x)\n",
    "        conv1 = self.relu(conv1)\n",
    "        conv1 = self.BN1(conv1)\n",
    "        conv1 = self.conv1b(conv1)\n",
    "        conv1 = self.relu(conv1)\n",
    "        conv1 = self.BN1(conv1)\n",
    "        pool1 = self.max_pool(conv1)\n",
    "        ##\n",
    "        conv2 = self.conv2a(pool1)\n",
    "        conv2 = self.relu(conv2)\n",
    "        conv2 = self.BN2(conv2)\n",
    "        conv2 = self.conv2b(conv2)\n",
    "        conv2 = self.relu(conv2)\n",
    "        conv2 = self.BN2(conv2)\n",
    "        pool2 = self.max_pool(conv2)\n",
    "        ##\n",
    "        conv3 = self.conv3a(pool2)\n",
    "        conv3 = self.relu(conv3)\n",
    "        conv3 = self.BN3(conv3)\n",
    "        conv3 = self.conv3b(conv3)\n",
    "        conv3 = self.relu(conv3)\n",
    "        conv3 = self.BN3(conv3)\n",
    "        pool3 = self.max_pool(conv3)\n",
    "        #\n",
    "        conv4 = self.conv4a(pool3)\n",
    "        conv4 = self.relu(conv4)\n",
    "        conv4 = self.BN4(conv4)\n",
    "        conv4 = self.conv4b(conv4)\n",
    "        conv4 = self.relu(conv4)\n",
    "        conv4 = self.BN4(conv4)\n",
    "        pool4 = self.max_pool(conv4)\n",
    "        ##\n",
    "        conv5 = self.conv5a(pool4)\n",
    "        conv5 = self.relu(conv5)\n",
    "        conv5 = self.conv5b(conv5)\n",
    "        conv5 = self.relu(conv5)\n",
    "        ##\n",
    "        up6 = torch.cat((self.upconv1(conv5),conv4),dim=1)\n",
    "        conv6 = self.conv6a(up6)\n",
    "        conv6 = self.conv6b(conv6)\n",
    "        ##\n",
    "        up7 = torch.cat((self.upconv2(conv6),conv3),dim=1)\n",
    "        conv7 = self.conv7a(up7)\n",
    "        conv7 = self.conv7b(conv7)\n",
    "        ##\n",
    "        up8 = torch.cat((self.upconv3(conv7),conv2),dim=1)\n",
    "        conv8 = self.conv8a(up8)\n",
    "        conv8 = self.conv8b(conv8)\n",
    "        ##\n",
    "        up9 = torch.cat((self.upconv4(conv8),conv1),dim=1)\n",
    "        conv9 = self.conv9a(up9)\n",
    "        conv9 = self.conv9b(conv9)\n",
    "        ##\n",
    "        conv10 = self.convLast(conv9)\n",
    "#         conv10 = conv10.view(-1,input_size[1]*input_size[2]*input_size[3])\n",
    "        return conv10\n",
    "          \n",
    "          \n",
    "          \n",
    "##########################################################################\n",
    "model = Net().to(device)#not necessary to add to device\n",
    "# summary(model, input_size=input_size)        \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes=2\n",
    "# input_size=(1, 128, 128, 128)\n",
    "# input_size[1]*input_size[2]*input_size[3]\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        \n",
    "        \n",
    "        #For first layer input(_,320,320,128)\n",
    "        self.conv1a=nn.Conv3d(in_channels=1, out_channels=32, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv1b=nn.Conv3d(in_channels=32, out_channels=32, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.BN1=nn.BatchNorm3d(32)\n",
    "        \n",
    "        #For second layer (_,160,160,64)\n",
    "        self.conv2a=nn.Conv3d(in_channels=32, out_channels=64, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv2b=nn.Conv3d(in_channels=64, out_channels=64, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.BN2=nn.BatchNorm3d(64)\n",
    "        \n",
    "        #For third layer (80,80,32)\n",
    "        self.conv3a=nn.Conv3d(in_channels=64, out_channels=128, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv3b=nn.Conv3d(in_channels=128, out_channels=128, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.BN3=nn.BatchNorm3d(128)\n",
    "        \n",
    "        #For forth layer \n",
    "        self.conv4a=nn.Conv3d(in_channels=128, out_channels=256, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv4b=nn.Conv3d(in_channels=256, out_channels=256, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.BN4=nn.BatchNorm3d(256)\n",
    "        \n",
    "        #For Upsampling/ seventh layer\n",
    "        self.upconv1=nn.ConvTranspose3d(in_channels=256, out_channels=128, kernel_size=(2,2,2), stride=2, padding=0)\n",
    "        self.conv5a=nn.Conv3d(in_channels=256, out_channels=128, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv5b=nn.Conv3d(in_channels=128, out_channels=128, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        \n",
    "        #For Upsampling/ eighth layer\n",
    "        self.upconv2=nn.ConvTranspose3d(in_channels=128, out_channels=64, kernel_size=(2,2,2), stride=2, padding=0)\n",
    "        self.conv6a=nn.Conv3d(in_channels=128, out_channels=64, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv6b=nn.Conv3d(in_channels=64, out_channels=64, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "\n",
    "        #For Upsampling/ ninth layer\n",
    "        self.upconv3=nn.ConvTranspose3d(in_channels=64, out_channels=32, kernel_size=(2,2,2), stride=2, padding=0)\n",
    "        self.conv7a=nn.Conv3d(in_channels=64, out_channels=32, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        self.conv7b=nn.Conv3d(in_channels=32, out_channels=32, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        \n",
    "        #For last layer\n",
    "        self.convLast=nn.Conv3d(in_channels=32, out_channels=num_of_classes, kernel_size=(3,3,3), stride=1, padding=1)\n",
    "        \n",
    "        #For maxpool\n",
    "        self.max_pool=nn.MaxPool3d(kernel_size=(2,2,2), stride=2)\n",
    "        \n",
    "        #For activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        conv1 = self.conv1a(x)\n",
    "        conv1 = self.relu(conv1)\n",
    "        conv1 = self.BN1(conv1)\n",
    "        conv1 = self.conv1b(conv1)\n",
    "        conv1 = self.relu(conv1)\n",
    "        conv1 = self.BN1(conv1)\n",
    "        pool1 = self.max_pool(conv1)\n",
    "        ##\n",
    "        conv2 = self.conv2a(pool1)\n",
    "        conv2 = self.relu(conv2)\n",
    "        conv2 = self.BN2(conv2)\n",
    "        conv2 = self.conv2b(conv2)\n",
    "        conv2 = self.relu(conv2)\n",
    "        conv2 = self.BN2(conv2)\n",
    "        pool2 = self.max_pool(conv2)\n",
    "        ##\n",
    "        conv3 = self.conv3a(pool2)\n",
    "        conv3 = self.relu(conv3)\n",
    "        conv3 = self.BN3(conv3)\n",
    "        conv3 = self.conv3b(conv3)\n",
    "        conv3 = self.relu(conv3)\n",
    "        conv3 = self.BN3(conv3)\n",
    "        pool3 = self.max_pool(conv3)\n",
    "        #\n",
    "        conv4 = self.conv4a(pool3)\n",
    "        conv4 = self.relu(conv4)\n",
    "        conv4 = self.conv4b(conv4)\n",
    "        conv4 = self.relu(conv4)\n",
    "        ##\n",
    "        up5 = torch.cat((self.upconv1(conv4),conv3),dim=1)\n",
    "        conv5 = self.conv5a(up5)\n",
    "        conv5 = self.conv5b(conv5)\n",
    "        ##\n",
    "        up6 = torch.cat((self.upconv2(conv5),conv2),dim=1)\n",
    "        conv6 = self.conv6a(up6)\n",
    "        conv6 = self.conv6b(conv6)\n",
    "        ##\n",
    "        up6 = torch.cat((self.upconv3(conv6),conv1),dim=1)\n",
    "        conv7 = self.conv7a(up6)\n",
    "        conv7 = self.conv7b(conv7)\n",
    "        ##\n",
    "        conv8 = self.convLast(conv7)\n",
    "        return conv7\n",
    "          \n",
    "          \n",
    "          \n",
    "##########################################################################\n",
    "model = Net().to(device)#not necessary to add to device\n",
    "# summary(model, input_size=input_size)        \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "X=np.load('./X_cardiac.npy')\n",
    "X=X.reshape(X.shape[0],1,X.shape[1],X.shape[2],X.shape[3])\n",
    "X_whitened = np.zeros(X.shape)\n",
    "for i in range(X.shape[0]):\n",
    "    temp1=X[i]\n",
    "    temp2=(temp1 - np.mean(temp1))/(np.std(temp1))\n",
    "    X_whitened[i]=temp2\n",
    "\n",
    "Y=np.load('./Y_cardiac.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_train_cardiac is : (16, 1, 320, 320, 128)\n",
      "The shape of x_test_cardiac is : (4, 1, 320, 320, 128)\n",
      "The shape of y_train_cardiac is : (16, 320, 320, 128)\n",
      "The shape of y_test_cardiac is : (4, 320, 320, 128)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_whitened, Y, test_size=0.20)\n",
    "print('The shape of x_train_cardiac is :',x_train.shape)\n",
    "print('The shape of x_test_cardiac is :',x_test.shape)\n",
    "print('The shape of y_train_cardiac is :',y_train.shape)\n",
    "print('The shape of y_test_cardiac is :',y_test.shape)\n",
    "x_train = torch.from_numpy(x_train)\n",
    "x_test = torch.from_numpy(x_test)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.TensorDataset(x_train,y_train)# create your datset\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True)\n",
    "\n",
    "valset = torch.utils.data.TensorDataset(x_test,y_test)# create your datset\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate and number of  epochs\n",
    "num_of_epochs = 1\n",
    "lr=1e-4\n",
    "\n",
    "# Loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()#NO NEED TO BE USING SOFTMAX WHEN USING Crioss Entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6b2c9bd9b8c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m#Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e3c8be441a27>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mpool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBN2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         return F.conv3d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 421\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "total_step = len(trainloader)\n",
    "for epochs in range(num_of_epochs):\n",
    "    for i, (images, labels) in enumerate(trainloader):  \n",
    "            #CHECK THE SHAPE OF BOTH IMAGES AND LABELS\n",
    "            images = images.to(device)\n",
    "            images= images.float()\n",
    "            labels = labels.to(device)  \n",
    "\n",
    "            #Forward pass\n",
    "            outputs = model(images)\n",
    "            labels = labels.long()\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Backpropagation and then optimization\n",
    "            optimizer.zero_grad()#Initially setting the gradient values to zero so backward() can find the gradient\n",
    "            loss.backward()#backpropagate and then optimize\n",
    "            optimizer.step()\n",
    "        #     if (i+1) % 50 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epochs+1, num_of_epochs, i+1, total_step, loss.item()))\n",
    "    torch.save(model, './cardiac')\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 320, 320, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = x_train[1]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
